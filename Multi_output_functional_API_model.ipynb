{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi output functional API model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_PgySJunoX-"
      },
      "source": [
        "Using Energy efficiency dataset to train the model.\\\n",
        "The dataset is available on UCI Machine Learning Repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHbLjzo4jxjG"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on8V9LDiYXhu"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Input\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v42sTf3hyQn",
        "outputId": "1c9b94d0-d1dc-49b8-d1c6-2068580db418"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lLuc6maLGOd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "a2c34f91-5fa3-4c69-e852-3c0e6289f641"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ENB2012_data.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>Y1</th>\n",
              "      <th>Y2</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.55</td>\n",
              "      <td>21.33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.90</td>\n",
              "      <td>563.5</td>\n",
              "      <td>318.5</td>\n",
              "      <td>122.50</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.84</td>\n",
              "      <td>28.28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     X1     X2     X3      X4   X5  ...   X8     Y1     Y2  Unnamed: 10  Unnamed: 11\n",
              "0  0.98  514.5  294.0  110.25  7.0  ...  0.0  15.55  21.33          NaN          NaN\n",
              "1  0.98  514.5  294.0  110.25  7.0  ...  0.0  15.55  21.33          NaN          NaN\n",
              "2  0.98  514.5  294.0  110.25  7.0  ...  0.0  15.55  21.33          NaN          NaN\n",
              "3  0.98  514.5  294.0  110.25  7.0  ...  0.0  15.55  21.33          NaN          NaN\n",
              "4  0.90  563.5  318.5  122.50  7.0  ...  0.0  20.84  28.28          NaN          NaN\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBLmOmvi8_4Z",
        "outputId": "35359f03-a35f-4f74-c9b1-a28564b81efd"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1296, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFw1hahJ83f4",
        "outputId": "c568abfb-44a9-43fa-97cb-b0c2baaabff3"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "X1              528\n",
              "X2              528\n",
              "X3              528\n",
              "X4              528\n",
              "X5              528\n",
              "X6              528\n",
              "X7              528\n",
              "X8              528\n",
              "Y1              528\n",
              "Y2              528\n",
              "Unnamed: 10    1296\n",
              "Unnamed: 11    1296\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Dpk6fbkQKw"
      },
      "source": [
        "The dataset has 8 independent features and 2 dependent features.\\\n",
        "Removing the unwanted columns and rows with NULL entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fECSjI4f9Jp5",
        "outputId": "3449325d-690e-426e-e7b3-0620c1578193"
      },
      "source": [
        "df.drop(['Unnamed: 10','Unnamed: 11'],axis='columns',inplace=True)\n",
        "df.dropna(axis = 'rows', inplace=True)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "A9313WlNLe3D",
        "outputId": "7181f248-7a2a-4059-ad0c-7215aaa16cde"
      },
      "source": [
        "x = df.iloc[:,:8]\n",
        "y1 = df['Y1']\n",
        "y2 = df['Y2']\n",
        "x.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.90</td>\n",
              "      <td>563.5</td>\n",
              "      <td>318.5</td>\n",
              "      <td>122.50</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     X1     X2     X3      X4   X5   X6   X7   X8\n",
              "0  0.98  514.5  294.0  110.25  7.0  2.0  0.0  0.0\n",
              "1  0.98  514.5  294.0  110.25  7.0  3.0  0.0  0.0\n",
              "2  0.98  514.5  294.0  110.25  7.0  4.0  0.0  0.0\n",
              "3  0.98  514.5  294.0  110.25  7.0  5.0  0.0  0.0\n",
              "4  0.90  563.5  318.5  122.50  7.0  2.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcC0fkuwOqHC",
        "outputId": "1f92f89b-f44e-4941-c657-2f85ca0893f9"
      },
      "source": [
        "y1 = np.array(y1)\n",
        "y2 = np.array(y2)\n",
        "y1[:5],y2[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([15.55, 15.55, 15.55, 15.55, 20.84]),\n",
              " array([21.33, 21.33, 21.33, 21.33, 28.28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vri0bpIYPwTK",
        "outputId": "3c2e2ab8-bf69-415a-9768-8cea5ed016c2"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "std = StandardScaler()\n",
        "std.fit(x)\n",
        "x = std.transform(x)\n",
        "print(x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2.04177671 -1.78587489 -0.56195149 -1.47007664  1.         -1.34164079\n",
            " -1.76044698 -1.81457514]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSSJNprfRK9a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y1_train,y1_test,y2_train,y2_test = train_test_split(x,y1,y2,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0Oj8NoqRfPy",
        "outputId": "d65882ac-8d51-4340-d1f8-025a9e17915f"
      },
      "source": [
        "y1_train.shape,y2_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((614,), (614,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ6DBYdOB-jf"
      },
      "source": [
        "Models training and prediction using Functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGXuzfqb9iTF"
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "def build_model():\n",
        "  input = Input(shape=(8,))\n",
        "  dense1 = Dense(128,activation='relu')(input)\n",
        "  dense2 = Dense(64, activation = 'relu')(dense1)\n",
        "\n",
        "  output1 = Dense(1, name='out1')(dense2)\n",
        "  dense3 = Dense(32,activation = 'relu')(dense2)\n",
        "  output2 = Dense(1, name = 'out2')(dense3)\n",
        "\n",
        "  model = Model(inputs=input,outputs=[output1,output2])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E95_6osm9iWX"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQnQxY0v9iYK"
      },
      "source": [
        "model.compile(optimizer='adam',loss = {'out1':'mse','out2':'mse'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8-BQwq39imE",
        "outputId": "10df4248-1ee1-4cdc-999c-4269b8760ce8"
      },
      "source": [
        "his = model.fit(x = x_train, y=[y1_train,y2_train],epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 2ms/step - loss: 1289.8102 - out1_loss: 593.8955 - out2_loss: 695.9148\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 1139.9880 - out1_loss: 501.4126 - out2_loss: 638.5754\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 733.0480 - out1_loss: 331.3527 - out2_loss: 401.6953\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 237.4710 - out1_loss: 139.4625 - out2_loss: 98.0085\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 116.6005 - out1_loss: 55.7468 - out2_loss: 60.8537\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 75.3352 - out1_loss: 34.2225 - out2_loss: 41.1127\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 67.7224 - out1_loss: 30.8642 - out2_loss: 36.8582\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 53.5623 - out1_loss: 24.4901 - out2_loss: 29.0722\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 48.2886 - out1_loss: 21.9679 - out2_loss: 26.3207\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 48.9435 - out1_loss: 23.0905 - out2_loss: 25.8529\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 44.6386 - out1_loss: 20.1922 - out2_loss: 24.4464\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 41.9593 - out1_loss: 19.6686 - out2_loss: 22.2907\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 38.5922 - out1_loss: 17.7033 - out2_loss: 20.8889\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 34.9969 - out1_loss: 15.9893 - out2_loss: 19.0076\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 32.4451 - out1_loss: 15.8744 - out2_loss: 16.5707\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 29.8012 - out1_loss: 13.6989 - out2_loss: 16.1023\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 27.8811 - out1_loss: 12.8336 - out2_loss: 15.0474\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 29.1188 - out1_loss: 12.7282 - out2_loss: 16.3905\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 26.6057 - out1_loss: 12.1535 - out2_loss: 14.4522\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 27.1516 - out1_loss: 12.1387 - out2_loss: 15.0129\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 22.1657 - out1_loss: 10.3425 - out2_loss: 11.8232\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 21.2224 - out1_loss: 9.4800 - out2_loss: 11.7424\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 22.8116 - out1_loss: 10.3896 - out2_loss: 12.4220\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 21.7164 - out1_loss: 9.9768 - out2_loss: 11.7396\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 19.6468 - out1_loss: 8.4415 - out2_loss: 11.2052\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 19.3748 - out1_loss: 8.7505 - out2_loss: 10.6243\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 18.3028 - out1_loss: 7.8597 - out2_loss: 10.4431\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 17.8133 - out1_loss: 8.1047 - out2_loss: 9.7087\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 17.7261 - out1_loss: 8.1452 - out2_loss: 9.5809\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 18.3628 - out1_loss: 8.2292 - out2_loss: 10.1336\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 16.7193 - out1_loss: 7.5154 - out2_loss: 9.2040\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 17.3395 - out1_loss: 7.5144 - out2_loss: 9.8251\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 19.5324 - out1_loss: 8.5294 - out2_loss: 11.0031\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 18.6631 - out1_loss: 8.3663 - out2_loss: 10.2968\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 16.9714 - out1_loss: 7.4946 - out2_loss: 9.4768\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 16.7486 - out1_loss: 7.4094 - out2_loss: 9.3392\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 14.4847 - out1_loss: 6.4729 - out2_loss: 8.0118\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 16.3523 - out1_loss: 6.9579 - out2_loss: 9.3943\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 15.9993 - out1_loss: 7.1510 - out2_loss: 8.8483\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 16.5657 - out1_loss: 6.8456 - out2_loss: 9.7201\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 16.9767 - out1_loss: 7.3901 - out2_loss: 9.5866\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 16.5266 - out1_loss: 7.1868 - out2_loss: 9.3399\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 17.3965 - out1_loss: 7.3362 - out2_loss: 10.0603\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 14.7001 - out1_loss: 6.5835 - out2_loss: 8.1167\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 14.9252 - out1_loss: 6.8594 - out2_loss: 8.0658\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 13.4724 - out1_loss: 5.8128 - out2_loss: 7.6596\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 14.2272 - out1_loss: 6.6697 - out2_loss: 7.5576\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 14.3232 - out1_loss: 6.3860 - out2_loss: 7.9372\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 15.3684 - out1_loss: 7.0915 - out2_loss: 8.2769\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 13.6877 - out1_loss: 5.8676 - out2_loss: 7.8201\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 14.4862 - out1_loss: 6.1430 - out2_loss: 8.3432\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 13.6821 - out1_loss: 6.0612 - out2_loss: 7.6209\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 13.4936 - out1_loss: 5.7589 - out2_loss: 7.7347\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 13.0310 - out1_loss: 5.7168 - out2_loss: 7.3142\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 14.0233 - out1_loss: 6.4645 - out2_loss: 7.5588\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 14.4376 - out1_loss: 6.2605 - out2_loss: 8.1771\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 13.5156 - out1_loss: 5.9269 - out2_loss: 7.5887\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 14.7466 - out1_loss: 7.0682 - out2_loss: 7.6784\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 11.6014 - out1_loss: 5.5445 - out2_loss: 6.0569\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 12.2581 - out1_loss: 5.7241 - out2_loss: 6.5340\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 12.0499 - out1_loss: 5.5813 - out2_loss: 6.4687\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 11.9461 - out1_loss: 5.4409 - out2_loss: 6.5052\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 11.3618 - out1_loss: 5.1123 - out2_loss: 6.2495\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 11.8976 - out1_loss: 5.2228 - out2_loss: 6.6748\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 13.7569 - out1_loss: 5.8142 - out2_loss: 7.9427\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 11.2100 - out1_loss: 5.1791 - out2_loss: 6.0308\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 11.8934 - out1_loss: 5.2405 - out2_loss: 6.6529\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 12.0497 - out1_loss: 5.2027 - out2_loss: 6.8470\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 11.6847 - out1_loss: 5.0469 - out2_loss: 6.6379\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 10.5049 - out1_loss: 4.8056 - out2_loss: 5.6993\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 11.2078 - out1_loss: 4.8293 - out2_loss: 6.3785\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 11.1409 - out1_loss: 5.1067 - out2_loss: 6.0342\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 11.0082 - out1_loss: 5.0270 - out2_loss: 5.9812\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.9137 - out1_loss: 4.7696 - out2_loss: 5.1441\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 11.0301 - out1_loss: 5.0471 - out2_loss: 5.9830\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 10.8987 - out1_loss: 4.8517 - out2_loss: 6.0469\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 9.9811 - out1_loss: 4.3737 - out2_loss: 5.6074\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 11.8232 - out1_loss: 4.9084 - out2_loss: 6.9149\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 10.4757 - out1_loss: 4.6463 - out2_loss: 5.8295\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 10.4024 - out1_loss: 4.5585 - out2_loss: 5.8439\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.8918 - out1_loss: 4.2937 - out2_loss: 5.5981\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 10.0778 - out1_loss: 4.7638 - out2_loss: 5.3139\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 9.1754 - out1_loss: 3.8620 - out2_loss: 5.3133\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 9.7560 - out1_loss: 4.2766 - out2_loss: 5.4794\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 9.4423 - out1_loss: 3.8756 - out2_loss: 5.5667\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 12.2408 - out1_loss: 5.4370 - out2_loss: 6.8038\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 10.4516 - out1_loss: 4.2064 - out2_loss: 6.2452\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 10.7329 - out1_loss: 4.6076 - out2_loss: 6.1254\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.6366 - out1_loss: 4.1529 - out2_loss: 5.4836\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 9.1076 - out1_loss: 3.8347 - out2_loss: 5.2729\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 9.5112 - out1_loss: 4.1634 - out2_loss: 5.3478\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 10.7512 - out1_loss: 4.4813 - out2_loss: 6.2699\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 10.6676 - out1_loss: 4.4554 - out2_loss: 6.2122\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 8.6074 - out1_loss: 3.5156 - out2_loss: 5.0917\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 8.9634 - out1_loss: 3.9260 - out2_loss: 5.0374\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 9.8315 - out1_loss: 4.0682 - out2_loss: 5.7633\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 9.4112 - out1_loss: 4.0620 - out2_loss: 5.3492\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.2837 - out1_loss: 3.6809 - out2_loss: 4.6027\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 9.5092 - out1_loss: 3.9615 - out2_loss: 5.5477\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8.7338 - out1_loss: 3.4489 - out2_loss: 5.2849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joZRVQCG9ior"
      },
      "source": [
        "y_pred=model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYdFnOWR9iqu",
        "outputId": "53f5c584-4f1c-48d4-f586-46dfdb5ab857"
      },
      "source": [
        "len(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ZWgznFSGzo",
        "outputId": "541d111b-992e-47c5-c499-1d3e554b237e"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error as mse\n",
        "print('Error for y1: ', mse(y_pred[0],y1_test))\n",
        "print('Error for y2: ', mse(y_pred[1],y2_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error for y1:  4.505285977111166\n",
            "Error for y2:  5.263034222730879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZFgwUSyBsDA",
        "outputId": "107dc32f-56aa-41ef-9e99-4a397e8947c8"
      },
      "source": [
        "print('Predicted values: ',y_pred[0][:5])\n",
        "print('Actual values: ',y1_test[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted values:  [[14.178672]\n",
            " [12.26509 ]\n",
            " [16.640678]\n",
            " [40.35176 ]\n",
            " [12.589118]]\n",
            "Actual values:  [14.62 12.12 16.44 40.57 11.34]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv1mvS0yBsHG",
        "outputId": "3cf5d45b-3b53-4f92-8101-b312c72f0ce1"
      },
      "source": [
        "print('Predicted values: ',y_pred[1][:5])\n",
        "print('Actual values: ',y2_test[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted values:  [[15.817106]\n",
            " [14.428451]\n",
            " [16.812025]\n",
            " [38.348125]\n",
            " [15.129458]]\n",
            "Actual values:  [16.88 14.97 17.1  40.47 14.87]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFtxFxR_CuX0"
      },
      "source": [
        "Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWq8cVYECwqf",
        "outputId": "09bde318-d644-487f-daab-d99bcc5f842d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "his_dict = his.history\n",
        "his_dict.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'out1_loss', 'out2_loss'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "S-Nt3tyACwue",
        "outputId": "0e2ea2aa-3c2f-4548-c868-22ce4ff11f70"
      },
      "source": [
        "loss1 = his.history['out1_loss']\n",
        "loss2 = his.history['out2_loss']\n",
        "epochs = list(range(1,len(loss1)+1))\n",
        "plt.plot(epochs,loss1,'b',label='LOSS 1')\n",
        "plt.plot(epochs,loss2,'g',label='LOSS 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKJRgHsx_xJK"
      },
      "source": [
        "Since the error corresponding to y2 is very high, we use a different model to train and tune the parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2fnaKswMRjz"
      },
      "source": [
        "Using custom model and custom loss function for model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlkY7dyPCw52"
      },
      "source": [
        "from keras.layers import Layer\n",
        "\n",
        "# custom dense layer\n",
        "class SimpleDense(Layer):\n",
        "  def __init__(self, units=32, activation= None):  # by default a dense layer of 32 units\n",
        "    super(SimpleDense, self).__init__()\n",
        "    self.units = units\n",
        "    self.activation = tf.keras.activations.get(activation)\n",
        "    \n",
        "  def build(self, input_shape):  # Initializing trainable weights and biases\n",
        "    w_init = tf.random_normal_initializer()\n",
        "    self.w = tf.Variable(name = 'kernel', initial_value = w_init(shape = (input_shape[-1],self.units),dtype = 'float32'), trainable= True)\n",
        "\n",
        "    b_init = tf.zeros_initializer()\n",
        "    self.b = tf.Variable(name = 'bias', initial_value = b_init(shape = (self.units,),dtype = 'float32'), trainable= True)\n",
        "\n",
        "  def call(self, inputs):  # defines computation, called by constructor of the class\n",
        "    return(self.activation(tf.matmul(inputs,self.w)+self.b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBNiZEm4Mbfl"
      },
      "source": [
        "# custom loss function: huber loss\n",
        "from keras.losses import Loss\n",
        "class myHuberLoss(Loss):\n",
        "  threshold = 0.5\n",
        "  def __init__(self, threshold):\n",
        "    super().__init__()\n",
        "    self.threshold = threshold\n",
        "  \n",
        "  def call(self,y_true,y_pred):\n",
        "    error = y_true-y_pred\n",
        "    is_small_error = tf.abs(error)<=self.threshold\n",
        "    small_error_loss = tf.square(error)*0.1\n",
        "    big_error_loss = self.threshold * (tf.abs(error)- 0.5 * self.threshold)\n",
        "    return tf.where(is_small_error, small_error_loss, big_error_loss)  # (condition, if true, else)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdOV04PVMbhy"
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "def build_model2():\n",
        "  model = Sequential([\n",
        "                      Dense(16, activation='relu', input_shape = (8,)),\n",
        "                      SimpleDense(units=32, activation = 'relu'),\n",
        "                      SimpleDense(units = 64, activation = 'relu'),\n",
        "                      SimpleDense(1)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvKshTKw1Y3-"
      },
      "source": [
        "model2 = build_model2()\n",
        "model2.compile(optimizer= 'adam', loss = myHuberLoss(threshold=0.8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmTJeii51Y6P",
        "outputId": "5a788d1c-6cde-4f7a-cd8c-7fba6df3e7ed"
      },
      "source": [
        "his2 = model2.fit(x_train,y = y2_train, epochs=500, validation_split=0.1, callbacks= [keras.callbacks.EarlyStopping(patience=20, monitor = 'val_loss', restore_best_weights=True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "18/18 [==============================] - 1s 25ms/step - loss: 19.3724 - val_loss: 18.4254\n",
            "Epoch 2/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 19.2466 - val_loss: 17.9912\n",
            "Epoch 3/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 18.6333 - val_loss: 16.2405\n",
            "Epoch 4/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 15.9255 - val_loss: 11.0918\n",
            "Epoch 5/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.2590 - val_loss: 7.9742\n",
            "Epoch 6/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 7.5800 - val_loss: 5.5815\n",
            "Epoch 7/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 4.7716 - val_loss: 4.7620\n",
            "Epoch 8/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 4.3178 - val_loss: 4.1412\n",
            "Epoch 9/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 3.6007 - val_loss: 3.7698\n",
            "Epoch 10/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 3.4352 - val_loss: 3.5716\n",
            "Epoch 11/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9101 - val_loss: 3.2456\n",
            "Epoch 12/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.9587 - val_loss: 3.0488\n",
            "Epoch 13/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.7446 - val_loss: 2.9274\n",
            "Epoch 14/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.5300 - val_loss: 2.8340\n",
            "Epoch 15/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.3640 - val_loss: 2.6359\n",
            "Epoch 16/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.3423 - val_loss: 2.5434\n",
            "Epoch 17/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.2798 - val_loss: 2.4333\n",
            "Epoch 18/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.2785 - val_loss: 2.3298\n",
            "Epoch 19/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.8935 - val_loss: 2.2557\n",
            "Epoch 20/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9521 - val_loss: 2.1769\n",
            "Epoch 21/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.8621 - val_loss: 2.1497\n",
            "Epoch 22/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.9724 - val_loss: 2.0333\n",
            "Epoch 23/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.0490 - val_loss: 2.0133\n",
            "Epoch 24/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.9645 - val_loss: 1.9567\n",
            "Epoch 25/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.8683 - val_loss: 1.9428\n",
            "Epoch 26/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.8649 - val_loss: 1.8963\n",
            "Epoch 27/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.8090 - val_loss: 1.8815\n",
            "Epoch 28/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.8082 - val_loss: 1.8280\n",
            "Epoch 29/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.7920 - val_loss: 1.8405\n",
            "Epoch 30/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.8027 - val_loss: 1.7767\n",
            "Epoch 31/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6823 - val_loss: 1.7883\n",
            "Epoch 32/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6837 - val_loss: 1.7366\n",
            "Epoch 33/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.7288 - val_loss: 1.7477\n",
            "Epoch 34/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6585 - val_loss: 1.7491\n",
            "Epoch 35/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6199 - val_loss: 1.7199\n",
            "Epoch 36/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6395 - val_loss: 1.6734\n",
            "Epoch 37/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4860 - val_loss: 1.6427\n",
            "Epoch 38/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.5899 - val_loss: 1.6331\n",
            "Epoch 39/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6200 - val_loss: 1.6135\n",
            "Epoch 40/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.5261 - val_loss: 1.5899\n",
            "Epoch 41/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.5587 - val_loss: 1.5925\n",
            "Epoch 42/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6136 - val_loss: 1.5916\n",
            "Epoch 43/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.5241 - val_loss: 1.5523\n",
            "Epoch 44/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.5731 - val_loss: 1.5228\n",
            "Epoch 45/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6604 - val_loss: 1.5146\n",
            "Epoch 46/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.5064 - val_loss: 1.5263\n",
            "Epoch 47/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4517 - val_loss: 1.5041\n",
            "Epoch 48/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4098 - val_loss: 1.4728\n",
            "Epoch 49/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4489 - val_loss: 1.4747\n",
            "Epoch 50/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3329 - val_loss: 1.5215\n",
            "Epoch 51/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6452 - val_loss: 1.4526\n",
            "Epoch 52/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4428 - val_loss: 1.4855\n",
            "Epoch 53/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4820 - val_loss: 1.4511\n",
            "Epoch 54/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4616 - val_loss: 1.4230\n",
            "Epoch 55/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4775 - val_loss: 1.4357\n",
            "Epoch 56/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4581 - val_loss: 1.4145\n",
            "Epoch 57/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3952 - val_loss: 1.5050\n",
            "Epoch 58/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.5309 - val_loss: 1.4507\n",
            "Epoch 59/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4292 - val_loss: 1.4156\n",
            "Epoch 60/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2830 - val_loss: 1.4013\n",
            "Epoch 61/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3620 - val_loss: 1.4018\n",
            "Epoch 62/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4121 - val_loss: 1.4407\n",
            "Epoch 63/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4357 - val_loss: 1.4069\n",
            "Epoch 64/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3887 - val_loss: 1.4644\n",
            "Epoch 65/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4297 - val_loss: 1.3841\n",
            "Epoch 66/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2492 - val_loss: 1.3667\n",
            "Epoch 67/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3880 - val_loss: 1.3641\n",
            "Epoch 68/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3382 - val_loss: 1.3680\n",
            "Epoch 69/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4683 - val_loss: 1.3864\n",
            "Epoch 70/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2582 - val_loss: 1.4020\n",
            "Epoch 71/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.5523 - val_loss: 1.3748\n",
            "Epoch 72/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3308 - val_loss: 1.3506\n",
            "Epoch 73/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3108 - val_loss: 1.3906\n",
            "Epoch 74/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3157 - val_loss: 1.4029\n",
            "Epoch 75/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3710 - val_loss: 1.3172\n",
            "Epoch 76/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3465 - val_loss: 1.3014\n",
            "Epoch 77/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2704 - val_loss: 1.3260\n",
            "Epoch 78/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2626 - val_loss: 1.3195\n",
            "Epoch 79/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3244 - val_loss: 1.3168\n",
            "Epoch 80/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4434 - val_loss: 1.2979\n",
            "Epoch 81/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2514 - val_loss: 1.2941\n",
            "Epoch 82/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3588 - val_loss: 1.3107\n",
            "Epoch 83/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3196 - val_loss: 1.3128\n",
            "Epoch 84/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4278 - val_loss: 1.2912\n",
            "Epoch 85/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3423 - val_loss: 1.2943\n",
            "Epoch 86/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2530 - val_loss: 1.2940\n",
            "Epoch 87/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2790 - val_loss: 1.3077\n",
            "Epoch 88/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2861 - val_loss: 1.3010\n",
            "Epoch 89/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3087 - val_loss: 1.2911\n",
            "Epoch 90/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3332 - val_loss: 1.2930\n",
            "Epoch 91/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2370 - val_loss: 1.3131\n",
            "Epoch 92/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3098 - val_loss: 1.3213\n",
            "Epoch 93/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1714 - val_loss: 1.2796\n",
            "Epoch 94/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1971 - val_loss: 1.3008\n",
            "Epoch 95/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3409 - val_loss: 1.3221\n",
            "Epoch 96/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2948 - val_loss: 1.3490\n",
            "Epoch 97/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2947 - val_loss: 1.3125\n",
            "Epoch 98/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3387 - val_loss: 1.3243\n",
            "Epoch 99/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3170 - val_loss: 1.2823\n",
            "Epoch 100/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2374 - val_loss: 1.2802\n",
            "Epoch 101/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3258 - val_loss: 1.2814\n",
            "Epoch 102/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2773 - val_loss: 1.3475\n",
            "Epoch 103/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3797 - val_loss: 1.2716\n",
            "Epoch 104/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2674 - val_loss: 1.2949\n",
            "Epoch 105/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2668 - val_loss: 1.2772\n",
            "Epoch 106/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2855 - val_loss: 1.2699\n",
            "Epoch 107/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.1976 - val_loss: 1.2817\n",
            "Epoch 108/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2507 - val_loss: 1.2766\n",
            "Epoch 109/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2189 - val_loss: 1.2633\n",
            "Epoch 110/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3024 - val_loss: 1.2923\n",
            "Epoch 111/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2571 - val_loss: 1.2677\n",
            "Epoch 112/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2719 - val_loss: 1.2815\n",
            "Epoch 113/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2263 - val_loss: 1.2902\n",
            "Epoch 114/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1932 - val_loss: 1.3009\n",
            "Epoch 115/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2561 - val_loss: 1.3010\n",
            "Epoch 116/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2175 - val_loss: 1.2866\n",
            "Epoch 117/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2882 - val_loss: 1.2890\n",
            "Epoch 118/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1721 - val_loss: 1.2595\n",
            "Epoch 119/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2588 - val_loss: 1.3931\n",
            "Epoch 120/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3096 - val_loss: 1.3243\n",
            "Epoch 121/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2773 - val_loss: 1.2590\n",
            "Epoch 122/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3508 - val_loss: 1.2447\n",
            "Epoch 123/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3527 - val_loss: 1.2762\n",
            "Epoch 124/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4436 - val_loss: 1.2841\n",
            "Epoch 125/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2549 - val_loss: 1.2413\n",
            "Epoch 126/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2007 - val_loss: 1.2226\n",
            "Epoch 127/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1847 - val_loss: 1.2546\n",
            "Epoch 128/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2317 - val_loss: 1.2756\n",
            "Epoch 129/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2944 - val_loss: 1.2444\n",
            "Epoch 130/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1002 - val_loss: 1.2394\n",
            "Epoch 131/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1440 - val_loss: 1.2536\n",
            "Epoch 132/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2923 - val_loss: 1.2201\n",
            "Epoch 133/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2529 - val_loss: 1.2183\n",
            "Epoch 134/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2104 - val_loss: 1.2311\n",
            "Epoch 135/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1467 - val_loss: 1.2601\n",
            "Epoch 136/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2358 - val_loss: 1.2266\n",
            "Epoch 137/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1756 - val_loss: 1.3342\n",
            "Epoch 138/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3010 - val_loss: 1.2009\n",
            "Epoch 139/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1529 - val_loss: 1.2131\n",
            "Epoch 140/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2338 - val_loss: 1.2105\n",
            "Epoch 141/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2542 - val_loss: 1.2177\n",
            "Epoch 142/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1627 - val_loss: 1.2265\n",
            "Epoch 143/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2546 - val_loss: 1.2162\n",
            "Epoch 144/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2319 - val_loss: 1.2224\n",
            "Epoch 145/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1036 - val_loss: 1.2062\n",
            "Epoch 146/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3287 - val_loss: 1.2193\n",
            "Epoch 147/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3541 - val_loss: 1.2048\n",
            "Epoch 148/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2129 - val_loss: 1.1965\n",
            "Epoch 149/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2122 - val_loss: 1.1951\n",
            "Epoch 150/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1981 - val_loss: 1.2014\n",
            "Epoch 151/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2132 - val_loss: 1.1860\n",
            "Epoch 152/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3018 - val_loss: 1.2421\n",
            "Epoch 153/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0938 - val_loss: 1.1658\n",
            "Epoch 154/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1954 - val_loss: 1.1697\n",
            "Epoch 155/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1808 - val_loss: 1.2030\n",
            "Epoch 156/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2900 - val_loss: 1.2087\n",
            "Epoch 157/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3551 - val_loss: 1.2269\n",
            "Epoch 158/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2120 - val_loss: 1.2783\n",
            "Epoch 159/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2647 - val_loss: 1.2155\n",
            "Epoch 160/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.1599 - val_loss: 1.1820\n",
            "Epoch 161/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.1155 - val_loss: 1.2065\n",
            "Epoch 162/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2885 - val_loss: 1.1994\n",
            "Epoch 163/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2040 - val_loss: 1.1637\n",
            "Epoch 164/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1823 - val_loss: 1.2413\n",
            "Epoch 165/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2979 - val_loss: 1.1496\n",
            "Epoch 166/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1099 - val_loss: 1.1791\n",
            "Epoch 167/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1418 - val_loss: 1.1268\n",
            "Epoch 168/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1322 - val_loss: 1.1115\n",
            "Epoch 169/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1170 - val_loss: 1.1479\n",
            "Epoch 170/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1515 - val_loss: 1.0971\n",
            "Epoch 171/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1173 - val_loss: 1.1383\n",
            "Epoch 172/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2328 - val_loss: 1.1211\n",
            "Epoch 173/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2322 - val_loss: 1.1227\n",
            "Epoch 174/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1030 - val_loss: 1.0840\n",
            "Epoch 175/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0836 - val_loss: 1.0574\n",
            "Epoch 176/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0717 - val_loss: 1.0916\n",
            "Epoch 177/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1972 - val_loss: 1.0415\n",
            "Epoch 178/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0975 - val_loss: 1.1672\n",
            "Epoch 179/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2514 - val_loss: 1.0603\n",
            "Epoch 180/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1753 - val_loss: 1.0717\n",
            "Epoch 181/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2218 - val_loss: 1.0957\n",
            "Epoch 182/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1160 - val_loss: 1.0483\n",
            "Epoch 183/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2085 - val_loss: 1.0230\n",
            "Epoch 184/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1237 - val_loss: 1.0282\n",
            "Epoch 185/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1082 - val_loss: 1.0079\n",
            "Epoch 186/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1291 - val_loss: 1.1175\n",
            "Epoch 187/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0502 - val_loss: 1.0670\n",
            "Epoch 188/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0205 - val_loss: 0.9961\n",
            "Epoch 189/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0837 - val_loss: 1.0265\n",
            "Epoch 190/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1810 - val_loss: 0.9842\n",
            "Epoch 191/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1568 - val_loss: 0.9424\n",
            "Epoch 192/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0554 - val_loss: 1.0241\n",
            "Epoch 193/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1402 - val_loss: 0.9211\n",
            "Epoch 194/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0028 - val_loss: 0.9742\n",
            "Epoch 195/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1198 - val_loss: 0.9502\n",
            "Epoch 196/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0842 - val_loss: 0.9603\n",
            "Epoch 197/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9752 - val_loss: 0.9959\n",
            "Epoch 198/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0771 - val_loss: 0.9054\n",
            "Epoch 199/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0081 - val_loss: 0.8939\n",
            "Epoch 200/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1052 - val_loss: 0.9541\n",
            "Epoch 201/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0032 - val_loss: 0.8939\n",
            "Epoch 202/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9985 - val_loss: 0.9168\n",
            "Epoch 203/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1056 - val_loss: 0.8613\n",
            "Epoch 204/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9829 - val_loss: 0.8760\n",
            "Epoch 205/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9645 - val_loss: 0.9194\n",
            "Epoch 206/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1390 - val_loss: 0.9144\n",
            "Epoch 207/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9958 - val_loss: 0.8638\n",
            "Epoch 208/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9388 - val_loss: 0.8809\n",
            "Epoch 209/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0733 - val_loss: 0.8497\n",
            "Epoch 210/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0007 - val_loss: 0.8193\n",
            "Epoch 211/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9861 - val_loss: 0.8399\n",
            "Epoch 212/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8827 - val_loss: 0.8171\n",
            "Epoch 213/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9201 - val_loss: 0.8645\n",
            "Epoch 214/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9928 - val_loss: 0.7904\n",
            "Epoch 215/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9674 - val_loss: 0.8595\n",
            "Epoch 216/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9674 - val_loss: 0.8089\n",
            "Epoch 217/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9495 - val_loss: 0.8017\n",
            "Epoch 218/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9178 - val_loss: 0.7857\n",
            "Epoch 219/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9695 - val_loss: 0.8320\n",
            "Epoch 220/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9952 - val_loss: 0.8203\n",
            "Epoch 221/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9852 - val_loss: 0.7777\n",
            "Epoch 222/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8505 - val_loss: 0.7514\n",
            "Epoch 223/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0138 - val_loss: 0.7595\n",
            "Epoch 224/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9339 - val_loss: 0.7746\n",
            "Epoch 225/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9746 - val_loss: 0.8225\n",
            "Epoch 226/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9315 - val_loss: 0.7241\n",
            "Epoch 227/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8777 - val_loss: 0.7106\n",
            "Epoch 228/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9090 - val_loss: 0.7109\n",
            "Epoch 229/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9505 - val_loss: 0.7429\n",
            "Epoch 230/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8825 - val_loss: 0.6743\n",
            "Epoch 231/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8786 - val_loss: 0.6824\n",
            "Epoch 232/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0269 - val_loss: 0.7257\n",
            "Epoch 233/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8938 - val_loss: 0.6795\n",
            "Epoch 234/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8196 - val_loss: 0.6415\n",
            "Epoch 235/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9205 - val_loss: 0.6633\n",
            "Epoch 236/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9188 - val_loss: 0.6338\n",
            "Epoch 237/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9392 - val_loss: 0.6976\n",
            "Epoch 238/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7971 - val_loss: 0.6438\n",
            "Epoch 239/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9033 - val_loss: 0.6559\n",
            "Epoch 240/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8374 - val_loss: 0.6181\n",
            "Epoch 241/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8987 - val_loss: 0.6407\n",
            "Epoch 242/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7759 - val_loss: 0.5928\n",
            "Epoch 243/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7927 - val_loss: 0.6138\n",
            "Epoch 244/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - val_loss: 0.5931\n",
            "Epoch 245/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8218 - val_loss: 0.6480\n",
            "Epoch 246/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8268 - val_loss: 0.6197\n",
            "Epoch 247/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6775 - val_loss: 0.6176\n",
            "Epoch 248/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7624 - val_loss: 0.5825\n",
            "Epoch 249/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8444 - val_loss: 0.6100\n",
            "Epoch 250/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7437 - val_loss: 0.5571\n",
            "Epoch 251/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8056 - val_loss: 0.5412\n",
            "Epoch 252/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8212 - val_loss: 0.5629\n",
            "Epoch 253/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8718 - val_loss: 0.5942\n",
            "Epoch 254/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8917 - val_loss: 0.5924\n",
            "Epoch 255/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6834 - val_loss: 0.6002\n",
            "Epoch 256/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8665 - val_loss: 0.5612\n",
            "Epoch 257/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7610 - val_loss: 0.5495\n",
            "Epoch 258/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7487 - val_loss: 0.5534\n",
            "Epoch 259/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8081 - val_loss: 0.5412\n",
            "Epoch 260/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6865 - val_loss: 0.5142\n",
            "Epoch 261/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8057 - val_loss: 0.5371\n",
            "Epoch 262/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7380 - val_loss: 0.5387\n",
            "Epoch 263/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7202 - val_loss: 0.5742\n",
            "Epoch 264/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7863 - val_loss: 0.5337\n",
            "Epoch 265/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7946 - val_loss: 0.5293\n",
            "Epoch 266/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7763 - val_loss: 0.5317\n",
            "Epoch 267/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7472 - val_loss: 0.5658\n",
            "Epoch 268/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8759 - val_loss: 0.5012\n",
            "Epoch 269/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7253 - val_loss: 0.5016\n",
            "Epoch 270/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7860 - val_loss: 0.5128\n",
            "Epoch 271/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7270 - val_loss: 0.5764\n",
            "Epoch 272/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7924 - val_loss: 0.5201\n",
            "Epoch 273/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7296 - val_loss: 0.4808\n",
            "Epoch 274/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7041 - val_loss: 0.5137\n",
            "Epoch 275/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7118 - val_loss: 0.5102\n",
            "Epoch 276/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6278 - val_loss: 0.6171\n",
            "Epoch 277/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7935 - val_loss: 0.4929\n",
            "Epoch 278/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7689 - val_loss: 0.5345\n",
            "Epoch 279/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8178 - val_loss: 0.4763\n",
            "Epoch 280/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6845 - val_loss: 0.4862\n",
            "Epoch 281/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7944 - val_loss: 0.4592\n",
            "Epoch 282/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7247 - val_loss: 0.5153\n",
            "Epoch 283/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6892 - val_loss: 0.5384\n",
            "Epoch 284/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7409 - val_loss: 0.4767\n",
            "Epoch 285/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6668 - val_loss: 0.5323\n",
            "Epoch 286/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7814 - val_loss: 0.4912\n",
            "Epoch 287/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7358 - val_loss: 0.4715\n",
            "Epoch 288/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6889 - val_loss: 0.6442\n",
            "Epoch 289/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7797 - val_loss: 0.5240\n",
            "Epoch 290/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7201 - val_loss: 0.5724\n",
            "Epoch 291/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8179 - val_loss: 0.5063\n",
            "Epoch 292/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7433 - val_loss: 0.5003\n",
            "Epoch 293/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7461 - val_loss: 0.4901\n",
            "Epoch 294/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7508 - val_loss: 0.4928\n",
            "Epoch 295/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7359 - val_loss: 0.4967\n",
            "Epoch 296/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6757 - val_loss: 0.5275\n",
            "Epoch 297/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7323 - val_loss: 0.4487\n",
            "Epoch 298/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6702 - val_loss: 0.5369\n",
            "Epoch 299/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7400 - val_loss: 0.5057\n",
            "Epoch 300/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.8210 - val_loss: 0.4720\n",
            "Epoch 301/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6975 - val_loss: 0.4805\n",
            "Epoch 302/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7241 - val_loss: 0.5520\n",
            "Epoch 303/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7187 - val_loss: 0.5367\n",
            "Epoch 304/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7183 - val_loss: 0.4894\n",
            "Epoch 305/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6884 - val_loss: 0.5052\n",
            "Epoch 306/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8036 - val_loss: 0.5631\n",
            "Epoch 307/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7286 - val_loss: 0.4773\n",
            "Epoch 308/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6935 - val_loss: 0.5322\n",
            "Epoch 309/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7336 - val_loss: 0.5016\n",
            "Epoch 310/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7965 - val_loss: 0.5586\n",
            "Epoch 311/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7574 - val_loss: 0.4616\n",
            "Epoch 312/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6897 - val_loss: 0.4673\n",
            "Epoch 313/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6905 - val_loss: 0.4961\n",
            "Epoch 314/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6856 - val_loss: 0.5664\n",
            "Epoch 315/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6905 - val_loss: 0.4943\n",
            "Epoch 316/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7146 - val_loss: 0.5004\n",
            "Epoch 317/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6562 - val_loss: 0.5286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lGkkuhCMbj9"
      },
      "source": [
        "y_pred2 = model2.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Lk740Gh6R27",
        "outputId": "2a8f3319-4758-4698-dc71-10c77782d9a9"
      },
      "source": [
        "# Calculating the mean squared error\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "print('Error for y2: ', mse(y_pred2,y2_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error for y2:  3.6741492529416266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai4jM1pfCvy6",
        "outputId": "aea65617-d44e-4d6e-c3bb-e3b941c83f52"
      },
      "source": [
        "print('Predicted values: ',y_pred2[:5])\n",
        "print('Actual values: ', y2_test[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted values:  [[16.183826]\n",
            " [14.751948]\n",
            " [17.38741 ]\n",
            " [39.156754]\n",
            " [14.948108]]\n",
            "Actual values:  [16.88 14.97 17.1  40.47 14.87]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D4enJ0a6uLg"
      },
      "source": [
        "Visualisation of loss vs epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waTrldgb6R5M",
        "outputId": "a5d0b42e-9e97-4e51-a0e8-7cd3e251a132"
      },
      "source": [
        "his2.history.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'val_loss'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "lGbVG-6367JZ",
        "outputId": "25fd60b7-3db5-4612-b3ee-0ca578f3174f"
      },
      "source": [
        "loss2 = his2.history['loss']\n",
        "val_loss = his2.history['val_loss']\n",
        "epochs = list(range(1,len(loss2)+1))\n",
        "plt.plot(epochs,loss2,'b',label='LOSS model 2')\n",
        "plt.plot(epochs,val_loss,'go',label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mAZd2sT67MG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r322Y4EDSoI"
      },
      "source": [
        "Some small changes in loss fucntion improved the performance of the model. The updated huber loss function reduced the speed of updating weights and biases for smaller loss.\\\n",
        "Early stopping was used to restore the best parameters to train the model.\n",
        "\n",
        "Functional API was implemented, losses were compared. A custom dense layer was designed. The custom huber loss function improved the model performance by some extent."
      ]
    }
  ]
}